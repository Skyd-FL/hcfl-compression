{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"FL_with_CNN_with_AE_in_one_script_include_result_saver.ipynb","provenance":[{"file_id":"1Y8x0AfIJ6MwzyX0O7Q4fBm3LqyPBDlC3","timestamp":1615339131498}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"numeric-prophet"},"source":["# Initial Setting"],"id":"numeric-prophet"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:36.642035Z","start_time":"2021-02-19T07:35:34.746958Z"},"id":"steady-workstation","executionInfo":{"status":"ok","timestamp":1615428228458,"user_tz":-540,"elapsed":773,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import nest_asyncio\n","nest_asyncio.apply()\n","\n","import numpy as np\n","import tensorflow as tf\n","import random\n","\n","FRACTION=0.1\n","BATCH_SIZE = 10 # inf = -1\n","NUM_EPOCHS = 5 # fixed!\n","TRAINING_ROUNDS=18\n","\n","CLIENTS_SHUFFLE_PER_ROUND=False\n","#CLIENTS_SHUFFLE_PER_ROUND=True "],"id":"steady-workstation","execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0CjDJ_u6w0w","executionInfo":{"status":"ok","timestamp":1615428228853,"user_tz":-540,"elapsed":1158,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"7bed1cde-0d9e-4298-be8d-d083934f03c6"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"id":"C0CjDJ_u6w0w","execution_count":48,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7FaVt6Hn2CF4","executionInfo":{"status":"ok","timestamp":1615428228854,"user_tz":-540,"elapsed":1153,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import csv\r\n","import time\r\n","import sys\r\n","import os\r\n","\r\n","class ResultSaver :\r\n","  def __init__(self, header) : \r\n","    self.header=header\r\n","    now = time.localtime()\r\n","    self.result_file_name = \"%04d%02d%02d%02d%02d%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec) +'.csv'\r\n","    self.f=open('/content/drive/MyDrive/Federated-Learning/result_saver_'+self.result_file_name , 'w', newline='')\r\n","    self.wr=csv.writer(self.f)\r\n","    self.wr.writerow(header)\r\n","    self.content=[]\r\n"," \r\n","  def put_attr(self, attr) :\r\n","    self.content.append(attr)\r\n","\r\n","  def insert_row(self):\r\n","    try :\r\n","      if(len(self.content)!=len(self.header)):\r\n","        raise Exception('Error : not matched header length and row length')\r\n","      self.wr.writerow(self.content)\r\n","    except Exception as e:\r\n","      print(e)\r\n","      self.content.clear()\r\n","      self.f.close()\r\n","      os.rename('/content/drive/MyDrive/Federated-Learning/result_saver_'+self.result_file_name, '/content/drive/MyDrive/Federated-Learning/'+'fail_'+'result_saver_'+self.result_file_name)\r\n","      sys.exit(99)\r\n","    finally :\r\n","      self.content.clear()\r\n","\r\n","  def close_result_saver(self) :\r\n","    self.f.close()\r\n","\r\n","#------------------------------------------------------------\r\n","\r\n","rs=ResultSaver([\"training_system\",\r\n","                \"compress_ratio\",\r\n","                \"max_round\",\r\n","                \"select_user_ratio\",\r\n","                \"total_user\",\r\n","                \"batch_size\",\r\n","                \"epoch\",\r\n","                \"round\",\r\n","                \"fl_accuracy\"\r\n","                ])\r\n","\r\n","# rs.put_attr(\"1\")\r\n","# rs.put_attr(\"2\")\r\n","# rs.insert_row()\r\n","# \r\n","# rs.close_result_saver()\r\n","# \r\n","# sys.exit()"],"id":"7FaVt6Hn2CF4","execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3H44nGV42vkd"},"source":["# AutoEncoder for reducing parameter number"],"id":"3H44nGV42vkd"},{"cell_type":"code","metadata":{"id":"rOArgDsm2rfH","executionInfo":{"status":"ok","timestamp":1615428228854,"user_tz":-540,"elapsed":1150,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["from tensorflow.keras import layers, losses\r\n","from tensorflow.keras.datasets import fashion_mnist\r\n","from tensorflow.keras.models import Model\r\n","\r\n","def get_compression_ratio(ratio=\"1:8\", ae_input_shape=(25, 32), ae_dense_input_shape=(16, 32)): # It's okay to change shape into numpy array\r\n","  seperate_ratio_numerator, seperate_ratio_denominator =  [int(string_el) for string_el in ratio.split(\":\")]\r\n","  ae_end_of_encoder_layer_size=ae_input_shape[0]*(ae_input_shape[1]*(seperate_ratio_numerator/seperate_ratio_denominator))\r\n","  ae_dense_end_of_encoder_layer_size=ae_dense_input_shape[0]*(ae_dense_input_shape[1]*(seperate_ratio_numerator/seperate_ratio_denominator))\r\n","  return int(ae_end_of_encoder_layer_size), int(ae_dense_end_of_encoder_layer_size)\r\n","\r\n","compression_ratio = \"1:8\"\r\n","\r\n","ae_end_of_encoder_layer_size, ae_dense_end_of_encoder_layer_size=get_compression_ratio(ratio=compression_ratio)\r\n","\r\n","class Autoencoder(Model):\r\n","  def __init__(self):\r\n","    super(Autoencoder, self).__init__()\r\n","    self.encoder = tf.keras.Sequential([\r\n","      layers.Flatten(), # make origianl 2-dim to 1-dim\r\n","      layers.Dense(25*16, activation='relu'),\r\n","      layers.Dense(25*8, activation='relu'),\r\n","      layers.Dense(ae_end_of_encoder_layer_size, activation='relu'), #### ex) 1:8 -> 25*4\r\n","    ])\r\n","    self.decoder = tf.keras.Sequential([\r\n","      # input dim is 64\r\n","      layers.Dense(25*8, activation='relu'),\r\n","      layers.Dense(25*16, activation='relu'),\r\n","      layers.Dense(25*32, activation='relu'), # It match the encode-flatten()\r\n","      layers.Reshape((25, 32)) # restore 1-dim to 2-dim\r\n","    ])\r\n","\r\n","  def call(self, x):\r\n","    encoded = self.encoder(x)\r\n","    decoded = self.decoder(encoded)\r\n","    return decoded\r\n","\r\n","autoencoder = Autoencoder()\r\n","\r\n","class Autoencoder_dense_training(Model):\r\n","  def __init__(self):\r\n","    super(Autoencoder_dense_training, self).__init__()\r\n","    self.encoder = tf.keras.Sequential([\r\n","      layers.Flatten(), # make origianl 2-dim to 1-dim\r\n","      layers.Dense(16*16, activation='tanh'),\r\n","      layers.Dense(16*8, activation='tanh'),\r\n","      layers.Dense(ae_dense_end_of_encoder_layer_size, activation='tanh'), #### ex) 1:8 -> 16*4\r\n","    ])\r\n","    self.decoder = tf.keras.Sequential([\r\n","      # input dim is 64\r\n","      layers.Dense(16*8, activation='tanh'),\r\n","      layers.Dense(16*16, activation='tanh'),\r\n","      layers.Dense(16*32, activation='tanh'), # It match the encode-flatten()\r\n","      # layers.Reshape((16, 32)) # restore 1-dim to 2-dim\r\n","    ])\r\n","\r\n","  def call(self, x):\r\n","    encoded = self.encoder(x)\r\n","    decoded = self.decoder(encoded)\r\n","    return decoded\r\n","\r\n","autoencoder_dense = Autoencoder_dense_training()\r\n","\r\n","autoencoder_dense.compile(optimizer='adam', loss=losses.MeanSquaredError())"],"id":"rOArgDsm2rfH","execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWsTlUcZ46E1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615428228855,"user_tz":-540,"elapsed":1149,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"4623c0a5-15ac-45df-829b-d6d03daf8d70"},"source":["autoencoder.load_weights(\"/content/drive/MyDrive/Federated-Learning/ae_1000_exam_weights.ckpt\")"],"id":"DWsTlUcZ46E1","execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd4893efc50>"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7PmWpaQSb0d","executionInfo":{"status":"ok","timestamp":1615428228855,"user_tz":-540,"elapsed":1144,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"cab35685-0cb1-4544-b742-68914fd30227"},"source":["autoencoder_dense.load_weights(\"/content/drive/MyDrive/Federated-Learning/Model-Parameter/ae_1000_exam_weights.ckpt\")"],"id":"d7PmWpaQSb0d","execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd4d0163e90>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"polished-pottery"},"source":["# Make Preprocessed-(I.I.D)Dataset"],"id":"polished-pottery"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:37.209748Z","start_time":"2021-02-19T07:35:36.653981Z"},"scrolled":true,"id":"macro-portugal","executionInfo":{"status":"ok","timestamp":1615428229474,"user_tz":-540,"elapsed":1759,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() # This dataset is not \"E\"mnist. Don't confuse!\n","\n","raw_dataset_for_iid=list(zip(mnist_train[0].reshape(-1, 28, 28, 1).astype(\"float32\")/255.0, mnist_train[1].astype(\"float32\")))\n","random.shuffle(raw_dataset_for_iid)\n","\n","el_size=600\n","temp_list_for_image=[]\n","temp_list_for_label=[]\n","federated_train_data_for_iid=[]\n","for idx, el in enumerate(raw_dataset_for_iid) :\n","    temp_list_for_image.append(el[0])\n","    temp_list_for_label.append(el[1])\n","    if (idx+1)%(el_size)==0 :\n","        federated_train_data_for_iid.append((np.array(temp_list_for_image, dtype=\"float32\"), np.array(temp_list_for_label, dtype=\"float32\")))\n","        temp_list_for_image=[]\n","        temp_list_for_label=[]\n","        \n","federated_train_data = federated_train_data_for_iid"],"id":"macro-portugal","execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"decimal-infection"},"source":["# Make MNIST-CNN 99% model using Keras"],"id":"decimal-infection"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:37.314958Z","start_time":"2021-02-19T07:35:37.210618Z"},"id":"invalid-customer","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615428229475,"user_tz":-540,"elapsed":1757,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"bce7bb0a-8fd8-4b1c-9d2b-a79a60945eb7"},"source":["keras_model= tf.keras.models.Sequential([\n","    tf.keras.Input(shape=(28, 28, 1)),\n","    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n","    \n","    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n","    \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(10, activation=\"softmax\"),\n","])\n","\n","keras_model.summary()\n","\n","keras_model.compile(\n","    optimizer = 'adam',\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics = ['accuracy']\n",")"],"id":"invalid-customer","execution_count":54,"outputs":[{"output_type":"stream","text":["Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 14, 14, 64)        51264     \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_11 (Flatten)         (None, 3136)              0         \n","_________________________________________________________________\n","dense_54 (Dense)             (None, 512)               1606144   \n","_________________________________________________________________\n","dense_55 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 1,663,370\n","Trainable params: 1,663,370\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"planned-diversity"},"source":["# Start Training"],"id":"planned-diversity"},{"cell_type":"code","metadata":{"id":"QHzzZNEtEABj","executionInfo":{"status":"ok","timestamp":1615428229475,"user_tz":-540,"elapsed":1753,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["# def encode_concat_parameter(parameter) :\r\n","#     layer1 = parameter[0].reshape(1,25,32)\r\n","#     encode_L1 = autoencoder.encoder(layer1).numpy()\r\n","\r\n","#     layer3 = parameter[2].reshape(800,64)\r\n","#     layer3_trans = layer3.transpose()\r\n","#     layer3_feed_ae = layer3.reshape(64,25,32)\r\n","#     encode_L3 = []\r\n","#     #for i in range(64):\r\n","#     encode_L3 = autoencoder.encoder(layer3_feed_ae).numpy() #.append(autoencoder.encoder(layer3_feed_ae).numpy())\r\n","\r\n","#     temp_list=[encode_L1,     # [layer1] #\r\n","#                parameter[1],\r\n","#                encode_L3,\r\n","#                parameter[3],\r\n","#                parameter[4],\r\n","#                parameter[5],\r\n","#                parameter[6],\r\n","#                parameter[7]\r\n","#                ] \r\n","\r\n","#     # for i in range(1,8) :\r\n","#     #   temp_list.append(parameter[i])\r\n","#     return temp_list\r\n","\r\n","# def decode_seperate_parameter(parameter) :\r\n","#     decoded_L1 = autoencoder.decoder(parameter[0]).numpy()  \r\n","#     L1_reshape = decoded_L1.reshape(5,5,1,32) #parameter[0].reshape(5,5,1,32) #\r\n","#     decoded_L3 = []\r\n","#     # for j in range(64):\r\n","#     decoded_L3 = autoencoder.decoder(parameter[2]).numpy() #.append(autoencoder.decoder(parameter[2]).numpy())\r\n","    \r\n","#     decoded_L3_np = np.array(decoded_L3)\r\n","#     layer3_reshape_out_ae = decoded_L3_np.reshape(64,800) #parameter[2].reshape(64,800)\r\n","#     layer3_before_trans = layer3_reshape_out_ae.transpose()\r\n","#     layer3_original = layer3_before_trans.reshape(5,5,32,64)\r\n","    \r\n","#     temp_list = [L1_reshape,\r\n","#                  parameter[1],\r\n","#                  layer3_original, #parameter[2],\r\n","#                  parameter[3],\r\n","#                  parameter[4],\r\n","#                  parameter[5],\r\n","#                  parameter[6],\r\n","#                  parameter[7],\r\n","#                  ]\r\n","\r\n","#     # for i in range(1, 8) :\r\n","#     #   temp_list.append(parameter[i])\r\n","#     return temp_list"],"id":"QHzzZNEtEABj","execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"ro8TTG8VHIE4","executionInfo":{"status":"ok","timestamp":1615428229475,"user_tz":-540,"elapsed":1751,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["def encode_concat_parameter(parameter) :\r\n","    # Process of 1st Layer\r\n","    layer1 = parameter[0].reshape(1,25,32)\r\n","    encode_L1 = autoencoder.encoder(layer1).numpy()\r\n","    # Skip 2nd Layer\r\n","    # Process of 3rd Layer\r\n","    layer3 = parameter[2].reshape(800,64)\r\n","    layer3_trans = layer3.transpose()\r\n","    layer3_feed_ae = layer3.reshape(64,25,32)\r\n","    encode_L3 = []\r\n","    #for i in range(64):\r\n","    encode_L3 = autoencoder.encoder(layer3_feed_ae).numpy() #.append(autoencoder.encoder(layer3_feed_ae).numpy())\r\n","\r\n","    # Skip 4th Layer\r\n","    layer4 = parameter[3]\r\n","    # Process of 5th Layer\r\n","    layer5 = parameter[4].reshape(3136,512) # 5th layer don't need to be reshape\r\n","    encoded_L5 = autoencoder_dense.encoder(layer5).numpy() #.append(autoencoder.encoder(layer3_feed_ae).numpy())   layer5.reshape(3136,16,32)\r\n","    # Skip 6th Layer\r\n","    # Skip 7th Layer\r\n","    # Skip 8th Layer\r\n","\r\n","    temp_list=[encode_L1,     # [layer1] #\r\n","               parameter[1],\r\n","               encode_L3,\r\n","               parameter[3],\r\n","               encoded_L5, # parameter[4],\r\n","               parameter[5],\r\n","               parameter[6],\r\n","               parameter[7]\r\n","               ] \r\n","\r\n","    # for i in range(1,8) :\r\n","    #   temp_list.append(parameter[i])\r\n","    return temp_list\r\n","\r\n","def decode_seperate_parameter(parameter) :\r\n","    decoded_L1 = autoencoder.decoder(parameter[0]).numpy()  \r\n","    L1_reshape = decoded_L1.reshape(5,5,1,32) #parameter[0].reshape(5,5,1,32) #\r\n","    decoded_L3 = []\r\n","    # for j in range(64):\r\n","    decoded_L3 = autoencoder.decoder(parameter[2]).numpy() #.append(autoencoder.decoder(parameter[2]).numpy())\r\n","    decoded_L3_np = np.array(decoded_L3)\r\n","    layer3_reshape_out_ae = decoded_L3_np.reshape(64,800) #parameter[2].reshape(64,800)\r\n","    layer3_before_trans = layer3_reshape_out_ae.transpose()\r\n","    layer3_original = layer3_before_trans.reshape(5,5,32,64)\r\n","\r\n","    # Skip 4th Layer\r\n","    layer4 = parameter[3]\r\n","    # Process of 5th Layer\r\n","    layer5 = autoencoder_dense.decoder(parameter[4]).numpy() # parameter[4] # 5th layer don't need to be reshape\r\n","    decoded_L5 = layer5.reshape(3136,512) #autoencoder_dense.decoder(layer5).numpy() #.append(autoencoder.encoder(layer3_feed_ae).numpy())\r\n","    # Skip 6th Layer\r\n","    # Skip 7th Layer\r\n","    # Skip 8th Layer\r\n","    \r\n","    temp_list = [L1_reshape,\r\n","                 parameter[1],\r\n","                 layer3_original, #parameter[2],\r\n","                 parameter[3],\r\n","                 decoded_L5,      #parameter[4],\r\n","                 parameter[5],\r\n","                 parameter[6],\r\n","                 parameter[7],\r\n","                 ]\r\n","\r\n","    # for i in range(1, 8) :\r\n","    #   temp_list.append(parameter[i])\r\n","    return temp_list"],"id":"ro8TTG8VHIE4","execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:51.387033Z","start_time":"2021-02-19T07:35:37.315930Z"},"scrolled":true,"id":"together-linux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615428344040,"user_tz":-540,"elapsed":116313,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"8131d290-2f4e-4d3b-ce2b-eeeec1d53adc"},"source":["fl_system = \"mesd\"\n","\n","print(\"training_system:\", fl_system, \", compression ratio:\", compression_ratio)\n","print(\"max_round:\", TRAINING_ROUNDS)\n","\n","TOTAL_CLIENTS = len(federated_train_data)\n","SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\n","print(\"total client :\", TOTAL_CLIENTS, \", selected client :\", SELECTED_CLIENTS)\n","\n","# starting to training\n","selected_clients_list=clients_status_list=np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False) # that is relevant to 4-2 step.\n","\n","global_parameter=keras_model.get_weights() # actually, It is initial parameter...\n","encoded_global_parameter=encode_concat_parameter(global_parameter) #### encoder\n","\n","print(\"-- parameter shape --\")\n","for layer in global_parameter :\n","    print(layer.shape)\n","\n","list_of_local_parameter=[]\n","list_of_local_dataset_size=[]\n","list_of_local_accuracy=[]\n","list_of_local_loss=[]\n","\n","for round in range(TRAINING_ROUNDS) :\n","    print(\"\\n▶ Round\", round+1, \"◀\")\n","    rs.put_attr(fl_system) #### result_saver\n","    rs.put_attr(\"1:8\") #### result_saver\n","    rs.put_attr(TRAINING_ROUNDS) #### result_saver\n","    rs.put_attr(FRACTION) #### result_saver\n","    rs.put_attr(TOTAL_CLIENTS) #### result_saver\n","    rs.put_attr(BATCH_SIZE) #### result_saver\n","    rs.put_attr(NUM_EPOCHS) #### result_saver\n","    rs.put_attr(round+1) #### result_saver\n","    \n","        # check whether to apply shuffle mode per round\n","    if CLIENTS_SHUFFLE_PER_ROUND == True :\n","        selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\n","    #print(\"selected clients :\", selected_clients_list)\n","\n","        # recevie Local parameter.\n","    for client_dataset in selected_clients_list :\n","        train_images, train_labels=federated_train_data[client_dataset]\n","        \n","        decoded_global_parameter = decode_seperate_parameter(encoded_global_parameter)#### decoder\n","\n","        keras_model.set_weights(decoded_global_parameter)\n","        \n","        train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\n","            \n","        local_parameter=keras_model.get_weights()\n","        encoded_local_parameter= encode_concat_parameter(local_parameter) #### encoder\n","        list_of_local_parameter.append(encoded_local_parameter)\n","        list_of_local_dataset_size.append(len(train_images))\n","        list_of_local_accuracy.append(train_result.history[\"accuracy\"][-1])\n","        list_of_local_loss.append(train_result.history[\"loss\"][-1])\n","        \n","        #print(\"    clint ID :\", client_dataset, \"training complete.\")\n","        #print(\"        accuracy :\", train_result.history[\"accuracy\"][-1], \"- loss :\", train_result.history[\"loss\"][-1])\n","    \n","        #4-5. aggregate Local parameters.\n","    decoded_list_of_loca_parameter=[ decode_seperate_parameter(encoded_local_parameter) for encoded_local_parameter in list_of_local_parameter] #### decoder\n","    global_parameter = np.mean(decoded_list_of_loca_parameter, axis=0)\n","    encoded_global_parameter=encode_concat_parameter(global_parameter) #### encoder\n","\n","    #global_parameter = np.mean(list_of_local_parameter, axis=0)*np.sum)(list_of_local_dataset_size\n","    #print(\"global_parameter :\",global_parameter)\n","    current_mean_accuracy = np.mean(np.array(list_of_local_accuracy, dtype=\"float32\"))\n","    rs.put_attr(current_mean_accuracy) #### result_saver\n","    current_mean_loss = np.mean(np.array(list_of_local_loss, dtype=\"float32\"))\n","    print(f\"  evaluation mean : accuracy - {current_mean_accuracy}, loss - {current_mean_loss}\")   \n","    \n","    list_of_local_parameter.clear()\n","    list_of_local_dataset_size.clear()\n","    list_of_local_accuracy.clear()\n","    list_of_local_loss.clear()\n","    rs.insert_row() #### result_saver\n","    \n","print(\"\\n\\n▶▶▶ Round is over.\")\n","\n","\n","rs.close_result_saver()"],"id":"together-linux","execution_count":57,"outputs":[{"output_type":"stream","text":["training_system: mesd , compression ratio: 1:8\n","max_round: 18\n","total client : 100 , selected client : 10\n","-- parameter shape --\n","(5, 5, 1, 32)\n","(32,)\n","(5, 5, 32, 64)\n","(64,)\n","(3136, 512)\n","(512,)\n","(512, 10)\n","(10,)\n","\n","▶ Round 1 ◀\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order, subok=True)\n"],"name":"stderr"},{"output_type":"stream","text":["  evaluation mean : accuracy - 0.2003333568572998, loss - 2.091569185256958\n","\n","▶ Round 2 ◀\n","  evaluation mean : accuracy - 0.1211666688323021, loss - 2.295294761657715\n","\n","▶ Round 3 ◀\n","  evaluation mean : accuracy - 0.11666665971279144, loss - 2.2951853275299072\n","\n","▶ Round 4 ◀\n","  evaluation mean : accuracy - 0.8801666498184204, loss - 0.3885549008846283\n","\n","▶ Round 5 ◀\n","  evaluation mean : accuracy - 0.9050000309944153, loss - 0.3044770359992981\n","\n","▶ Round 6 ◀\n","  evaluation mean : accuracy - 0.9379999041557312, loss - 0.19136306643486023\n","\n","▶ Round 7 ◀\n","  evaluation mean : accuracy - 0.9536666870117188, loss - 0.13894422352313995\n","\n","▶ Round 8 ◀\n","  evaluation mean : accuracy - 0.9616665840148926, loss - 0.12049627304077148\n","\n","▶ Round 9 ◀\n","  evaluation mean : accuracy - 0.9678333401679993, loss - 0.10664250701665878\n","\n","▶ Round 10 ◀\n","  evaluation mean : accuracy - 0.9706667065620422, loss - 0.09201148897409439\n","\n","▶ Round 11 ◀\n","  evaluation mean : accuracy - 0.971000075340271, loss - 0.09231776744127274\n","\n","▶ Round 12 ◀\n","  evaluation mean : accuracy - 0.9778333902359009, loss - 0.0744917243719101\n","\n","▶ Round 13 ◀\n","  evaluation mean : accuracy - 0.9776666760444641, loss - 0.07740272581577301\n","\n","▶ Round 14 ◀\n","  evaluation mean : accuracy - 0.9791666269302368, loss - 0.06837762892246246\n","\n","▶ Round 15 ◀\n","  evaluation mean : accuracy - 0.9798333048820496, loss - 0.060457903891801834\n","\n","▶ Round 16 ◀\n","  evaluation mean : accuracy - 0.9845000505447388, loss - 0.050858937203884125\n","\n","▶ Round 17 ◀\n","  evaluation mean : accuracy - 0.984000027179718, loss - 0.05222548916935921\n","\n","▶ Round 18 ◀\n","  evaluation mean : accuracy - 0.9838333129882812, loss - 0.054202646017074585\n","\n","\n","▶▶▶ Round is over.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"2IVjBhcgxQ_I","executionInfo":{"status":"error","timestamp":1615428344046,"user_tz":-540,"elapsed":116313,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"9b149f59-7d88-47e8-ad6b-dc11963afbcc"},"source":["import sys\r\n","sys.exit()"],"id":"2IVjBhcgxQ_I","execution_count":58,"outputs":[{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vaJJXbr01PmM","executionInfo":{"status":"aborted","timestamp":1615428344041,"user_tz":-540,"elapsed":116303,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import pandas as pd\r\n","fake_link = \"/content/drive/MyDrive/Federated-Learning/fl-model-static-dataset/parameter_set_20210227194250/round_000010/local_parameter_cli_43.xlsx\"\r\n","local_parameter = pd.read_excel(open(fake_link, 'rb'), index_col=0, sheet_name='dense_1')  "],"id":"vaJJXbr01PmM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWMnp4kTjipQ","executionInfo":{"status":"aborted","timestamp":1615428344041,"user_tz":-540,"elapsed":116299,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["dfr_sheet2 = pd.read_excel(open(fake_link, 'rb'), index_col=0, sheet_name='conv_layer2')  \r\n","layer3 = dfr_sheet2.to_numpy()\r\n","print(np.shape(layer3))"],"id":"IWMnp4kTjipQ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4ABfuAfj8BK","executionInfo":{"status":"aborted","timestamp":1615428344041,"user_tz":-540,"elapsed":116296,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["print(layer3.mean())\r\n","print(layer3.max()/layer3.mean())\r\n","print(layer3.min()/layer3.mean())\r\n","print(layer3.max())\r\n","print(layer3.min())"],"id":"y4ABfuAfj8BK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjM22BXq2FkM","executionInfo":{"status":"aborted","timestamp":1615428344042,"user_tz":-540,"elapsed":116294,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["layer5 = local_parameter.to_numpy()\r\n","print(np.shape(layer5))\r\n","print(layer5[0])\r\n"],"id":"DjM22BXq2FkM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaOe9unYfaM2","executionInfo":{"status":"aborted","timestamp":1615428344042,"user_tz":-540,"elapsed":116291,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["print(layer5.mean())\r\n","print(layer5.max()/layer5.mean())\r\n","print(layer5.min()/layer5.mean())\r\n","print(layer5.max())\r\n","print(layer5.min())"],"id":"yaOe9unYfaM2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sOc-4EslZJ5","executionInfo":{"status":"aborted","timestamp":1615428344043,"user_tz":-540,"elapsed":116289,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["print(global_parameter[4].mean())\r\n","print(global_parameter[4].max()/layer5.mean())\r\n","print(global_parameter[4].min()/layer5.mean())\r\n","print(global_parameter[4].max())\r\n","print(global_parameter[4].min())"],"id":"-sOc-4EslZJ5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHMR_00_jd4A","executionInfo":{"status":"aborted","timestamp":1615428344044,"user_tz":-540,"elapsed":116288,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import matplotlib.pyplot as plt\r\n","rng = np.random.RandomState(10)  # deterministic random data\r\n","a = np.hstack((rng.normal(size=1000),\r\n","               rng.normal(loc=5, scale=2, size=1000)))\r\n","_ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\r\n","plt.title(\"Histogram of neural network in LeNet-5\")\r\n","Text(0.5, 1.0, \"Histogram of neural network in LeNet-5\")\r\n","plt.show()"],"id":"QHMR_00_jd4A","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5m0BORGecdZc","executionInfo":{"status":"aborted","timestamp":1615428344044,"user_tz":-540,"elapsed":116285,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["encoded_L5 = autoencoder_dense.encoder(layer5[0].reshape(1,16,32)).numpy()\r\n","decoded_L5 = autoencoder_dense.decoder(encoded_L5).numpy()\r\n","print(decoded_L5.reshape(1,512))"],"id":"5m0BORGecdZc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMYe5GU2dDO1","executionInfo":{"status":"aborted","timestamp":1615428344044,"user_tz":-540,"elapsed":116282,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["MSE = np.square(np.subtract(layer5[0].reshape(1,16,32),decoded_L5.reshape(1,16,32))).mean() \r\n","print(MSE)"],"id":"lMYe5GU2dDO1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dqTKYoXiRHZ","executionInfo":{"status":"aborted","timestamp":1615428344045,"user_tz":-540,"elapsed":116281,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import matplotlib.pyplot as plt\r\n","\r\n","_ = plt.hist(layer5, bins='auto')  # arguments are passed to np.histogram\r\n","plt.title(\"Histogram of neural network in LeNet-5\")\r\n","plt.show()"],"id":"2dqTKYoXiRHZ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLSioXeishz4","executionInfo":{"status":"aborted","timestamp":1615428344045,"user_tz":-540,"elapsed":116277,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import matplotlib.pyplot as plt\r\n","\r\n","for i in range(3136):\r\n","  _ = plt.hist(layer5[i], bins='auto')  # arguments are passed to np.histogram\r\n","  plt.title(\"Histogram of neural network in LeNet-5\")\r\n","  plt.show()"],"id":"PLSioXeishz4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHre1tDKrKL9","executionInfo":{"status":"aborted","timestamp":1615428344045,"user_tz":-540,"elapsed":116274,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}}},"source":["import matplotlib.pyplot as plt\r\n","\r\n","_ = plt.hist(global_parameter[4], bins='auto')  # arguments are passed to np.histogram\r\n","plt.title(\"Histogram of neural network in LeNet-5\")\r\n","plt.show()"],"id":"lHre1tDKrKL9","execution_count":null,"outputs":[]}]}