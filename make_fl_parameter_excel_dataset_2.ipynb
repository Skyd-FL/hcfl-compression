{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"make_fl_parameter_excel_dataset.ipynb","provenance":[{"file_id":"1oXvo7gkJHSqr3F2KHh3W7EHgO-5cI8ZD","timestamp":1615021394040},{"file_id":"1yjsRLj-Eg8flgNA-MFZOeUnAfMx14ZS2","timestamp":1613721139494}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"numeric-prophet"},"source":["# Initial Setting"],"id":"numeric-prophet"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33bO0vK9sct8","executionInfo":{"status":"ok","timestamp":1614746962238,"user_tz":-540,"elapsed":16891,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"fd5b3ae3-576e-4fa7-b1cd-19b895522c6e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"33bO0vK9sct8","execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:36.642035Z","start_time":"2021-02-19T07:35:34.746958Z"},"id":"steady-workstation"},"source":["import nest_asyncio\n","nest_asyncio.apply()\n","\n","import numpy as np\n","import tensorflow as tf\n","import random\n","\n","FRACTION=0.1\n","BATCH_SIZE = 10 # inf = -1\n","NUM_EPOCHS = 5 # fixed!\n","TRAINING_ROUNDS=100\n","\n","CLIENTS_SHUFFLE_PER_ROUND=False\n","#CLIENTS_SHUFFLE_PER_ROUND=True "],"id":"steady-workstation","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:36.649992Z","start_time":"2021-02-19T07:35:36.643011Z"},"id":"dependent-evolution","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614746964227,"user_tz":-540,"elapsed":18872,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"e8ea1a88-8eb2-489c-a53e-667353f9bc71"},"source":["import os\n","import time\n","import sys\n","import csv\n","import pandas as pd\n","\n","class ParameterSaver:\n","    def __init__(self):\n","        self.save_path = \"/content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\"\n","        \n","        now = time.localtime()\n","        self.directory_name = \"parameter_set_\"+\"%04d%02d%02d%02d%02d%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n","        \n","        os.mkdir(os.path.join(self.save_path, self.directory_name))\n","        print(f\"{self.directory_name} directory is created in {self.save_path}\")\n","        \n","        self.current_round_directory_name=\"\"\n","\n","    def save_initial_parameter(self, initial_parameter) :\n","        np.savetxt(os.path.join(self.save_path, self.directory_name, \"initial_parameter.csv\"), initial_parameter, fmt='%s', delimiter=',')\n","        \n","    def round_start(self, round_number):\n","        self.current_round_directory_name=f\"round_{round_number:06d}\"\n","        os.mkdir(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name))\n","        \n","    def save_local_parameter(self, client_id, local_parameter) :\n","        #np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"local_parameter_cli_{client_id}.csv\"), local_parameter, fmt='%s', delimiter=',')\n","        # Each Sheet, split to 2D (axa) width + b (height)\n","        # 1st: [5*5=25 width] x [32 height] + [32 height]\n","        temp1 = local_parameter[0].reshape(25,32)\n","        temp2 = local_parameter[1].reshape(1,32)\n","        sheet1 = np.concatenate((temp1,temp2))\n","        df_sheet1 = pd.DataFrame(sheet1)\n","        # 2nd: [5*5*32 width] x [64 height] + [64 height]\n","        temp1 = local_parameter[2].reshape(5*5*32,64)\n","        temp2 = local_parameter[3].reshape(1,64)\n","        sheet2 = np.concatenate((temp1,temp2))\n","        df_sheet2 = pd.DataFrame(sheet2)\n","        #sheet2 = local_parameter[1].reshape(5*5*32 + 64)\n","        # 3rd: [3136 width] * [512 height] + [512 height]\n","        temp1 = local_parameter[4].reshape(3136,512)\n","        temp2 = local_parameter[5].reshape(1,512)\n","        sheet3 = np.concatenate((temp1,temp2))\n","        df_sheet3 = pd.DataFrame(sheet3)\n","        # 4th: [512 width] * [10 height] + [10 height]\n","        temp1 = local_parameter[6].reshape(512,10)\n","        temp2 = local_parameter[7].reshape(1,10)\n","        sheet4 = np.concatenate((temp1,temp2)) \n","        df_sheet4 = pd.DataFrame(sheet4)\n","        with pd.ExcelWriter(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"local_parameter_cli_{client_id}.xlsx\")) as writer:  \n","            df_sheet1.to_excel(writer, sheet_name='conv_layer1')\n","            df_sheet2.to_excel(writer, sheet_name='conv_layer2')\n","            df_sheet3.to_excel(writer, sheet_name='dense_1')\n","            df_sheet4.to_excel(writer, sheet_name='dense_2')\n","    def save_aggreated_global_parameter(self, aggregated_global_parameter) :\n","        # np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"aggregated_global_parameter.csv\"), aggregated_global_parameter, fmt='%s', delimiter=',')\n","        temp1 = local_parameter[0].reshape(25,32)\n","        temp2 = local_parameter[1].reshape(1,32)\n","        sheet1 = np.concatenate((temp1,temp2))\n","        df_sheet1 = pd.DataFrame(sheet1)\n","        # 2nd: [5*5*32 width] x [64 height] + [64 height]\n","        temp1 = local_parameter[2].reshape(5*5*32,64)\n","        temp2 = local_parameter[3].reshape(1,64)\n","        sheet2 = np.concatenate((temp1,temp2))\n","        df_sheet2 = pd.DataFrame(sheet2)\n","        #sheet2 = local_parameter[1].reshape(5*5*32 + 64)\n","        # 3rd: [3136 width] * [512 height] + [512 height]\n","        temp1 = local_parameter[4].reshape(3136,512)\n","        temp2 = local_parameter[5].reshape(1,512)\n","        sheet3 = np.concatenate((temp1,temp2))\n","        df_sheet3 = pd.DataFrame(sheet3)\n","        # 4th: [512 width] * [10 height] + [10 height]\n","        temp1 = local_parameter[6].reshape(512,10)\n","        temp2 = local_parameter[7].reshape(1,10)\n","        sheet4 = np.concatenate((temp1,temp2)) \n","        df_sheet4 = pd.DataFrame(sheet4)\n","        with pd.ExcelWriter(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"aggregated_global_parameter.xlsx\")) as writer:  \n","            df_sheet1.to_excel(writer, sheet_name='conv_layer1')\n","            df_sheet2.to_excel(writer, sheet_name='conv_layer2')\n","            df_sheet3.to_excel(writer, sheet_name='dense_1')\n","            df_sheet4.to_excel(writer, sheet_name='dense_2')\n","\n","\n","        \n","#---------------------------------------------------------------------------------\n","parameter_saver= ParameterSaver() # make directory for saving parameter set"],"id":"dependent-evolution","execution_count":null,"outputs":[{"output_type":"stream","text":["parameter_set_20210303044924 directory is created in /content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"polished-pottery"},"source":["# Make Preprocessed-(I.I.D)Dataset"],"id":"polished-pottery"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:37.209748Z","start_time":"2021-02-19T07:35:36.653981Z"},"scrolled":true,"id":"macro-portugal","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614746964886,"user_tz":-540,"elapsed":19526,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"77e615d1-96df-470c-f294-0c71f3f6ac7d"},"source":["mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() # This dataset is not \"E\"mnist. Don't confuse!\n","\n","raw_dataset_for_iid=list(zip(mnist_train[0].reshape(-1, 28, 28, 1).astype(\"float32\")/255.0, mnist_train[1].astype(\"float32\")))\n","random.shuffle(raw_dataset_for_iid)\n","\n","el_size=600\n","temp_list_for_image=[]\n","temp_list_for_label=[]\n","federated_train_data_for_iid=[]\n","for idx, el in enumerate(raw_dataset_for_iid) :\n","    temp_list_for_image.append(el[0])\n","    temp_list_for_label.append(el[1])\n","    if (idx+1)%(el_size)==0 :\n","        federated_train_data_for_iid.append((np.array(temp_list_for_image, dtype=\"float32\"), np.array(temp_list_for_label, dtype=\"float32\")))\n","        temp_list_for_image=[]\n","        temp_list_for_label=[]\n","        \n","federated_train_data = federated_train_data_for_iid"],"id":"macro-portugal","execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"decimal-infection"},"source":["# Make MNIST-CNN 99% model using Keras"],"id":"decimal-infection"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:37.314958Z","start_time":"2021-02-19T07:35:37.210618Z"},"id":"invalid-customer","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614746965380,"user_tz":-540,"elapsed":20013,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"b3e4b150-0b17-4e41-8f3b-f7a77bf95b31"},"source":["keras_model= tf.keras.models.Sequential([\n","    tf.keras.Input(shape=(28, 28, 1)),\n","    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n","    \n","    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n","    \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(10, activation=\"softmax\"),\n","])\n","\n","keras_model.summary()\n","\n","keras_model.compile(\n","    optimizer = 'adam',\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics = ['accuracy']\n",")"],"id":"invalid-customer","execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3136)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1606144   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,663,370\n","Trainable params: 1,663,370\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"planned-diversity"},"source":["# Start Training"],"id":"planned-diversity"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-19T07:35:51.387033Z","start_time":"2021-02-19T07:35:37.315930Z"},"scrolled":true,"id":"together-linux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614750494121,"user_tz":-540,"elapsed":3548750,"user":{"displayName":"이상민","photoUrl":"","userId":"10075919356116843705"}},"outputId":"4d924762-76b3-4641-afc7-ac74c505d9f9"},"source":["TOTAL_CLIENTS = len(federated_train_data)\n","SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\n","print(\"total client :\", TOTAL_CLIENTS, \", selected client :\", SELECTED_CLIENTS)\n","\n","# starting to training\n","selected_clients_list=clients_status_list=np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False) # that is relevant to 4-2 step.\n","\n","global_parameter=keras_model.get_weights()\n","parameter_saver.save_initial_parameter(global_parameter)\n","\n","print(\"-- prameter shape --\")\n","for layer in global_parameter :\n","    print(layer.shape)\n","\n","list_of_local_parameter=[]\n","list_of_local_dataset_size=[]\n","list_of_local_accuracy=[]\n","list_of_local_loss=[]\n","\n","#for round in range(TRAINING_ROUNDS) :\n","for round in range(93,TRAINING_ROUNDS) :\n","    print(\"\\n▶ Round\", round+1, \"◀\")\n","    parameter_saver.round_start(round+1)\n","    \n","        # check whether to apply shuffle mode per round\n","    if CLIENTS_SHUFFLE_PER_ROUND == True :\n","        selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\n","    #print(\"selected clients :\", selected_clients_list)\n","\n","        # recevie Local parameter.\n","    for client_dataset in selected_clients_list :\n","        train_images, train_labels=federated_train_data[client_dataset]\n","        \n","        keras_model.set_weights(global_parameter)\n","        \n","        train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\n","            \n","        local_parameter=keras_model.get_weights()\n","        list_of_local_parameter.append(local_parameter)\n","        parameter_saver.save_local_parameter(client_dataset, local_parameter)\n","        list_of_local_dataset_size.append(len(train_images))\n","        list_of_local_accuracy.append(train_result.history[\"accuracy\"][-1])\n","        list_of_local_loss.append(train_result.history[\"loss\"][-1])\n","        \n","        #print(\"    clint ID :\", client_dataset, \"training complete.\")\n","        #print(\"        accuracy :\", train_result.history[\"accuracy\"][-1], \"- loss :\", train_result.history[\"loss\"][-1])\n","    \n","        #4-5. aggregate Local parameters.\n","    global_parameter = np.mean(list_of_local_parameter, axis=0)\n","    #global_parameter = np.mean(list_of_local_parameter, axis=0)*np.sum(list_of_local_dataset_size)\n","    #print(\"global_parameter :\",global_parameter)\n","    parameter_saver.save_aggreated_global_parameter(global_parameter)\n","    current_mean_accuracy = np.mean(np.array(list_of_local_accuracy, dtype=\"float32\"))\n","    current_mean_loss = np.mean(np.array(list_of_local_loss, dtype=\"float32\"))\n","    print(f\"  evaluation mean : accuracy - {current_mean_accuracy}, loss - {current_mean_loss}\")   \n","    \n","    list_of_local_parameter.clear()\n","    list_of_local_dataset_size.clear()\n","    list_of_local_accuracy.clear()\n","    list_of_local_loss.clear()\n","    \n","print(\"\\n\\n▶▶▶ Round is over.\")"],"id":"together-linux","execution_count":null,"outputs":[{"output_type":"stream","text":["total client : 100 , selected client : 10\n","-- prameter shape --\n","(5, 5, 1, 32)\n","(32,)\n","(5, 5, 32, 64)\n","(64,)\n","(3136, 512)\n","(512,)\n","(512, 10)\n","(10,)\n","\n","▶ Round 94 ◀\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order, subok=True)\n"],"name":"stderr"},{"output_type":"stream","text":["  evaluation mean : accuracy - 0.9923332929611206, loss - 0.027462929487228394\n","\n","▶ Round 95 ◀\n","  evaluation mean : accuracy - 0.9979999661445618, loss - 0.00956199411302805\n","\n","▶ Round 96 ◀\n","  evaluation mean : accuracy - 0.9985000491142273, loss - 0.004739153664559126\n","\n","▶ Round 97 ◀\n","  evaluation mean : accuracy - 0.9985000491142273, loss - 0.00439043901860714\n","\n","▶ Round 98 ◀\n","  evaluation mean : accuracy - 0.999666690826416, loss - 0.001970861107110977\n","\n","▶ Round 99 ◀\n","  evaluation mean : accuracy - 0.9991666674613953, loss - 0.0022725150920450687\n","\n","▶ Round 100 ◀\n","  evaluation mean : accuracy - 0.9983333349227905, loss - 0.007015646900981665\n","\n","\n","▶▶▶ Round is over.\n"],"name":"stdout"}]}]}